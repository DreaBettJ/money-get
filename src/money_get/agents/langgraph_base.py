"""LangGraph Agent åŸºç±» - å¸¦å®Œæ•´å¯è§‚æµ‹æ€§"""
from abc import ABC, abstractmethod
from typing import TypedDict, Dict, Any, List, Optional
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain.agents import create_agent
from langfuse import Langfuse
import json
from pathlib import Path

from ..logger import logger as _logger

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent


def get_api_config() -> dict:
    """è·å– API é…ç½®"""
    config_path = PROJECT_ROOT.parent / "config.json"
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    llm_cfg = config.get("llm", {})
    llm_cfg["langfuse"] = config.get("langfuse", {})
    return llm_cfg


class AgentState(TypedDict):
    """Agent çŠ¶æ€"""
    stock_code: str
    data: dict
    analysis: str
    error: str
    messages: list


def create_base_llm():
    """åˆ›å»ºåŸºç¡€ LLM"""
    config = get_api_config()
    
    url = config.get("url", "https://api.minimax.chat/v1")
    base_url = url.replace("/text/chatcompletion_v2", "")
    
    llm = ChatOpenAI(
        model=config.get("model", "MiniMax-M2.5"),
        api_key=config.get("api_key", ""),
        base_url=base_url,
        temperature=0.3
    )
    return llm


def get_langfuse_handler():
    """è·å– Langfuse å¤„ç†å™¨"""
    config = get_api_config()
    langfuse_cfg = config.get("langfuse", {})
    
    if not langfuse_cfg.get("public_key"):
        return None
    
    return Langfuse(
        public_key=langfuse_cfg["public_key"],
        secret_key=langfuse_cfg["secret_key"]
    )


class LangGraphAgent:
    """LangGraph Agent åŸºç±»"""
    
    def __init__(self, name: str, system_prompt: str):
        self.name = name
        self.system_prompt = system_prompt
        self.llm = create_base_llm()
        self.graph = None
        self._build_graph()
    
    @abstractmethod
    def get_tools(self) -> List:
        """è·å–å·¥å…·åˆ—è¡¨ - å­ç±»å®ç°"""
        pass
    
    def _build_graph(self):
        """æ„å»ºå›¾"""
        from langchain.agents import create_agent
        
        tools = self.get_tools()
        self.agent = create_agent(
            self.llm,
            tools,
            system_prompt=self.system_prompt,
            checkpointer=MemorySaver()
        )
        
        _logger.info(f"ğŸ¤– [{self.name}] LangGraph Agent å·²åˆ›å»º")
        _logger.info(f"   å·¥å…·: {[t.name for t in tools]}")
    
    def analyze(self, stock_code: str, data: dict = None) -> str:
        """åˆ†æè‚¡ç¥¨"""
        _logger.info(f"ğŸ”¶ [{self.name}] å¼€å§‹åˆ†æ: {stock_code}")
        
        data = data or {}
        messages = [HumanMessage(content=self._build_prompt(stock_code, data))]
        
        config = {"configurable": {"thread_id": f"{self.name}_{stock_code}"}}
        
        try:
            result = self.agent.invoke({"messages": messages}, config)
            
            # è·å–æœ€ç»ˆå“åº”
            response = result["messages"][-1].content
            
            _logger.info(f"âœ… [{self.name}] å®Œæˆ: {stock_code}")
            _logger.info(f"   æ¶ˆæ¯æ•°: {len(result['messages'])}")
            
            return response
            
        except Exception as e:
            _logger.error(f"âŒ [{self.name}] å¤±è´¥: {e}")
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def _build_prompt(self, stock_code: str, data: dict) -> str:
        """æ„å»ºæç¤ºè¯ - å­ç±»å®ç°"""
        return f"åˆ†æè‚¡ç¥¨ {stock_code}"
    
    def get_graph_diagram(self) -> str:
        """è·å–å›¾ç»“æ„ï¼ˆMermaidï¼‰"""
        return self.agent.get_graph().draw_mermaid()


# ä¾¿æ·è£…é¥°å™¨
def data_tool(func):
    """æ•°æ®å·¥å…·è£…é¥°å™¨"""
    return tool(func)
