"""æ”¿ç­–å…³é”®è¯æå–ç³»ç»Ÿ V2

ä»æ”¿åºœå®˜ç½‘/æƒå¨åª’ä½“è·å–æ”¿ç­–æ–‡ä»¶ï¼Œæå–å…³é”®è¯
- æ—¶æ•ˆæ€§ï¼šæ–°æ”¿ç­–/æ—§æ”¿ç­–
- é‡è¦ç¨‹åº¦ï¼šå›½å®¶çº§/éƒ¨å§”çº§/åœ°æ–¹çº§
"""
import re
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from enum import Enum

# ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—é…ç½®
from money_get.core.logger import get_logger
logger = get_logger("money_get.policy")

# Playwright æ˜¯å¯é€‰ä¾èµ–
try:
    from playwright.sync_api import sync_playwright
    HAS_PLAYWRIGHT = True
except ImportError:
    HAS_PLAYWRIGHT = False
    logger.warning("âš ï¸ Playwright æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ•°æ®æºï¼Œæ”¿ç­–ä¿¡æ¯å¯èƒ½ä¸å®Œæ•´")
    logger.info("ğŸ’¡ å®‰è£… Playwright: pip install playwright && playwright install chromium")

# è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
REQUEST_DELAY = 2.0
_last_request_time = 0


class PolicyLevel(Enum):
    """æ”¿ç­–é‡è¦ç¨‹åº¦"""
    NATIONAL = "å›½å®¶çº§"      # å…šä¸­å¤®ã€å›½åŠ¡é™¢
    MINISTRY = "éƒ¨å§”çº§"      # å„éƒ¨å§”
    LOCAL = "åœ°æ–¹çº§"        # çœå¸‚


class PolicyTimeliness(Enum):
    """æ”¿ç­–æ—¶æ•ˆæ€§"""
    NEW = "æ–°æ”¿ç­–"          # 7å¤©å†…
    RECENT = "è¿‘æœŸ"         # 30å¤©å†…
    OLD = "æ—§æ”¿ç­–"          # 30å¤©å‰


def _delay():
    """æ§åˆ¶è¯·æ±‚é¢‘ç‡"""
    global _last_request_time
    elapsed = time.time() - _last_request_time
    if elapsed < REQUEST_DELAY:
        time.sleep(REQUEST_DELAY - elapsed)
    _last_request_time = time.time()


# é‡è¦ç¨‹åº¦å…³é”®è¯æ˜ å°„
LEVEL_KEYWORDS = {
    PolicyLevel.NATIONAL: [
        "å…šä¸­å¤®", "å›½åŠ¡é™¢", "ä¸­å…±ä¸­å¤®", "å…¨å›½", "ä¸­å¤®", "æ€»ä¹¦è®°", 
        "å›½åŠ¡é™¢å…³äº", "ä¸­å…±ä¸­å¤®åŠå…¬å…", "å›½åŠ¡é™¢åŠå…¬å…", "å…¨å›½äººå¤§",
        "åå››äº”", "2035", "è¿œæ™¯ç›®æ ‡", "è§„åˆ’çº²è¦"
    ],
    PolicyLevel.MINISTRY: [
        "å·¥ä¿¡éƒ¨", "å‘æ”¹å§”", "è´¢æ”¿éƒ¨", "å•†åŠ¡éƒ¨", "ç§‘æŠ€éƒ¨", "æ•™è‚²éƒ¨",
        "å«å¥å§”", "ç”Ÿæ€ç¯å¢ƒéƒ¨", "ä½å»ºéƒ¨", "äº¤é€šè¿è¾“éƒ¨", "å†œä¸šå†œæ‘éƒ¨",
        "å¤®è¡Œ", "è¯ç›‘ä¼š", "é“¶ä¿ç›‘ä¼š", "è‡ªç„¶èµ„æºéƒ¨", "æ–‡æ—…éƒ¨"
    ],
    PolicyLevel.LOCAL: [
        "çœ", "å¸‚", "å¿", "åŒº", "é•‡", "ä¹¡", "è‡ªæ²»åŒº", "ç›´è¾–å¸‚",
        "çœå§”", "å¸‚æ”¿åºœ", "åŒºå¿", "å¼€å‘åŒº"
    ]
}


# æ—¶é—´å…³é”®è¯
TIME_KEYWORDS = {
    PolicyTimeliness.NEW: ["ä»Šæ—¥", "æ˜¨å¤©", "æœ¬å‘¨", "æœ¬æœˆ", "æœ€æ–°", "åˆšåˆš"],
    PolicyTimeliness.RECENT: ["è¿‘æ—¥", "è¿‘æœŸ", "æœ¬æœˆ", "æœ¬å¹´", "ä»Šå¹´"],
}


def _extract_date_from_text(text: str) -> Optional[datetime]:
    """ä»æ–‡æœ¬ä¸­æå–æ—¥æœŸ"""
    # å¸¸è§æ—¥æœŸæ ¼å¼
    patterns = [
        r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
        r'(\d{4})-(\d{1,2})-(\d{1,2})',
        r'(\d{4})/(\d{1,2})/(\d{1,2})',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            try:
                return datetime(int(match.group(1)), int(match.group(2)), int(match.group(3)))
            except:
                pass
    
    return None


def _judge_level(title: str) -> PolicyLevel:
    """åˆ¤æ–­æ”¿ç­–é‡è¦ç¨‹åº¦"""
    title = title.lower()
    
    # å›½å®¶çº§ä¼˜å…ˆåŒ¹é…
    for keyword in LEVEL_KEYWORDS[PolicyLevel.NATIONAL]:
        if keyword in title:
            return PolicyLevel.NATIONAL
    
    # éƒ¨å§”çº§
    for keyword in LEVEL_KEYWORDS[PolicyLevel.MINISTRY]:
        if keyword in title:
            return PolicyLevel.MINISTRY
    
    # åœ°æ–¹çº§
    for keyword in LEVEL_KEYWORDS[PolicyLevel.LOCAL]:
        if keyword in title:
            return PolicyLevel.LOCAL
    
    return PolicyLevel.MINISTRY  # é»˜è®¤éƒ¨å§”çº§


def _judge_timeliness(title: str, text: str = "") -> PolicyTimeliness:
    """åˆ¤æ–­æ”¿ç­–æ—¶æ•ˆæ€§"""
    now = datetime.now()
    
    # 1. å°è¯•ä»æ–‡æœ¬æå–æ—¥æœŸ
    date = _extract_date_from_text(title + text)
    if date:
        days = (now - date).days
        if days <= 7:
            return PolicyTimeliness.NEW
        elif days <= 30:
            return PolicyTimeliness.RECENT
        else:
            return PolicyTimeliness.OLD
    
    # 2. ä»æ ‡é¢˜å…³é”®è¯åˆ¤æ–­
    for keyword in TIME_KEYWORDS[PolicyTimeliness.NEW]:
        if keyword in title:
            return PolicyTimeliness.NEW
    
    for keyword in TIME_KEYWORDS[PolicyTimeliness.RECENT]:
        if keyword in title:
            return PolicyTimeliness.RECENT
    
    # 3. é»˜è®¤è¿”å›è¿‘æœŸ
    return PolicyTimeliness.RECENT


def fetch_with_playwright(url: str, timeout: int = 30000) -> Optional[str]:
    """ç”¨ Playwright è·å–é¡µé¢"""
    if not HAS_PLAYWRIGHT:
        return None
    
    _delay()
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        try:
            page.goto(url, wait_until="networkidle", timeout=timeout)
            content = page.content()
            return content
        except Exception as e:
            logger.info(f"è·å–é¡µé¢å¤±è´¥: {url}, {e}")
            return None
        finally:
            browser.close()


def get_gov_policy_keywords() -> List[Dict]:
    """è·å–æ”¿åºœæ”¿ç­–å…³é”®è¯ï¼ˆå¸¦æ—¶æ•ˆæ€§å’Œé‡è¦ç¨‹åº¦ï¼‰
    
    ä»ä¸­å›½æ”¿åºœç½‘ã€æ–°åç½‘ç­‰è·å–æ”¿ç­–æ–‡ä»¶
    """
    if not HAS_PLAYWRIGHT:
        return _get_policy_fallback()
    
    keywords = []
    
    # 1. ä¸­å›½æ”¿åºœç½‘ - æ”¿ç­–æ–‡ä»¶
    logger.info("è·å–ä¸­å›½æ”¿åºœç½‘æ”¿ç­–...")
    content = fetch_with_playwright("https://www.gov.cn/zhengce/zuixin.htm")
    if content:
        policies = _extract_policy_info(content, "ä¸­å›½æ”¿åºœç½‘")
        keywords.extend(policies)
    
    # 2. å¤®å¹¿ç½‘ - æ”¿ç­–è§£è¯»
    logger.info("è·å–å¤®å¹¿ç½‘æ”¿ç­–...")
    content = fetch_with_playwright("https://news.cnr.cn/")
    if content:
        policies = _extract_policy_info(content, "å¤®å¹¿ç½‘")
        keywords.extend(policies)
    
    # å»é‡
    unique = _dedup_keywords(keywords)
    
    return unique[:30]


def _extract_policy_info(html: str, source: str) -> List[Dict]:
    """ä»HTMLä¸­æå–æ”¿ç­–ä¿¡æ¯"""
    keywords = []
    
    # æå–æ ‡é¢˜
    titles = re.findall(r'<a[^>]*>([^<]{6,50})</a>', html)
    
    for title in titles[:20]:
        title = title.strip()
        title = re.sub(r'&[a-z]+;', '', title)  # å»é™¤HTMLå®ä½“
        title = title.strip()
        
        # è¿‡æ»¤å™ªéŸ³
        if len(title) < 6:
            continue
        if any(x in title for x in ['ç™»å½•', 'æ³¨å†Œ', 'æ›´å¤š', '>>', 'å›¾ç‰‡', 'è§†é¢‘', 'æ»šåŠ¨', 'è¿”å›']):
            continue
        
        # åˆ¤æ–­é‡è¦ç¨‹åº¦
        level = _judge_level(title)
        
        # åˆ¤æ–­æ—¶æ•ˆæ€§
        timeliness = _judge_timeliness(title)
        
        # æå–è¡Œä¸šé¢†åŸŸ
        sectors = _extract_sectors(title)
        
        keywords.append({
            'title': title,
            'source': source,
            'sectors': sectors,
            'level': level.value,
            'timeliness': timeliness.value,
        })
    
    return keywords


def _extract_sectors(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–è¡Œä¸š/é¢†åŸŸ"""
    text = text.lower()
    
    sector_map = {
        'æ–°èƒ½æº': ['æ–°èƒ½æº', 'å…‰ä¼', 'é£ç”µ', 'å‚¨èƒ½', 'é”‚ç”µæ± ', 'ç”µåŠ¨è½¦', 'ç”µåŠ¨æ±½è½¦', 'æ±½è½¦', 'ç”µæ± '],
        'äººå·¥æ™ºèƒ½': ['äººå·¥æ™ºèƒ½', 'AI', 'å¤§æ¨¡å‹', 'ç®—åŠ›', 'èŠ¯ç‰‡', 'æ™ºèƒ½', 'æ•°å­—ç»æµ', 'ç§‘æŠ€'],
        'åŠå¯¼ä½“': ['åŠå¯¼ä½“', 'é›†æˆç”µè·¯', 'å…‰åˆ»æœº', 'èŠ¯ç‰‡'],
        'åŒ»è¯åŒ»ç–—': ['åŒ»è¯', 'åŒ»ç–—', 'ç”Ÿç‰©', 'ä¸­è¯', 'ç–«è‹—', 'åŒ»ç–—å™¨æ¢°', 'å¥åº·', 'å«ç”Ÿ'],
        'é«˜ç«¯åˆ¶é€ ': ['é«˜ç«¯åˆ¶é€ ', 'å·¥ä¸š', 'æœºå™¨äºº', 'æ•°æ§', 'è‡ªåŠ¨åŒ–', 'åˆ¶é€ ', 'è£…å¤‡'],
        'æ•°å­—ç»æµ': ['æ•°å­—', 'æ•°æ®', 'äº‘è®¡ç®—', 'å¤§æ•°æ®', 'äº’è”ç½‘', 'ç½‘ç»œ'],
        'ç»¿è‰²ä½ç¢³': ['ç»¿è‰²', 'ä½ç¢³', 'ç¢³ä¸­å’Œ', 'ç¢³è¾¾å³°', 'ç¯ä¿', 'èŠ‚èƒ½', 'ç”Ÿæ€'],
        'åŸºå»ºåœ°äº§': ['åŸºå»º', 'å»ºç­‘', 'æˆ¿åœ°äº§', 'åŸå¸‚', 'ç®¡ç½‘', 'æ°´æ³¥', 'å·¥ç¨‹'],
        'æ¶ˆè´¹': ['æ¶ˆè´¹', 'å®¶ç”µ', 'çººç»‡', 'é£Ÿå“', 'é¤é¥®', 'æ—…æ¸¸', 'é›¶å”®'],
        'é‡‘è': ['é‡‘è', 'é“¶è¡Œ', 'ä¿é™©', 'è¯åˆ¸', 'æŠ•èµ„', 'èµ„æœ¬'],
        'å†œä¸š': ['å†œä¸š', 'å†œæ‘', 'ä¹¡æ‘æŒ¯å…´', 'ç²®é£Ÿ', 'å†œäº§å“', 'å†œæœº'],
        'å›½é˜²': ['å›½é˜²', 'å†›å·¥', 'èˆªå¤©', 'èˆªç©º', 'èˆ¹èˆ¶', 'å†›äº‹'],
    }
    
    found = []
    for sector, keywords in sector_map.items():
        if any(k in text for k in keywords):
            if sector not in found:
                found.append(sector)
    
    return found


def _dedup_keywords(keywords: List[Dict]) -> List[Dict]:
    """å»é‡"""
    seen = set()
    unique = []
    
    for kw in keywords:
        key = kw['title'][:15]
        if key not in seen:
            seen.add(key)
            unique.append(kw)
    
    return unique


def _get_policy_fallback() -> List[Dict]:
    """å¤‡ç”¨æ–¹æ¡ˆï¼šæ— æ•°æ®æ—¶è¿”å›ç©º"""
    logger.warning("âš ï¸ æ— å¯ç”¨æ”¿ç­–æ•°æ®æºï¼Œè¯·å®‰è£… Playwright è·å–çœŸå®æ•°æ®")
    return []


def get_focus_sectors(policy_level: str = None, timeliness: str = None) -> List[str]:
    """è·å–å½“å‰æ”¿ç­–å…³æ³¨é¢†åŸŸ
    
    Args:
        policy_level: ç­›é€‰é‡è¦ç¨‹åº¦ (å›½å®¶çº§/éƒ¨å§”çº§/åœ°æ–¹çº§)
        timeliness: ç­›é€‰æ—¶æ•ˆæ€§ (æ–°æ”¿ç­–/è¿‘æœŸ/æ—§æ”¿ç­–)
    
    Returns:
        list: çƒ­é—¨è¡Œä¸šåˆ—è¡¨
    """
    policies = get_gov_policy_keywords()
    
    # è¿‡æ»¤
    if policy_level:
        policies = [p for p in policies if p.get('level') == policy_level]
    if timeliness:
        policies = [p for p in policies if p.get('timeliness') == timeliness]
    
    # ç»Ÿè®¡è¡Œä¸šå‡ºç°é¢‘æ¬¡
    sector_count = {}
    for p in policies:
        for sector in p.get('sectors', []):
            sector_count[sector] = sector_count.get(sector, 0) + 1
    
    # æŒ‰é¢‘æ¬¡æ’åº
    sorted_sectors = sorted(sector_count.items(), key=lambda x: x[1], reverse=True)
    
    return [s[0] for s in sorted_sectors[:10]]


def get_priority_policies(limit: int = 5) -> List[Dict]:
    """è·å–ä¼˜å…ˆæ”¿ç­–ï¼ˆæ–°æ”¿ç­– + å›½å®¶çº§ï¼‰
    
    Args:
        limit: è¿”å›æ•°é‡
    
    Returns:
        list: é«˜ä¼˜å…ˆçº§æ”¿ç­–åˆ—è¡¨
    """
    policies = get_gov_policy_keywords()
    
    # ä¼˜å…ˆçº§æ’åº
    def priority(p):
        score = 0
        # å›½å®¶çº§ +3ï¼Œéƒ¨å§”çº§ +2ï¼Œåœ°æ–¹çº§ +1
        if p.get('level') == 'å›½å®¶çº§':
            score += 3
        elif p.get('level') == 'éƒ¨å§”çº§':
            score += 2
        
        # æ–°æ”¿ç­– +2ï¼Œè¿‘æœŸ +1
        if p.get('timeliness') == 'æ–°æ”¿ç­–':
            score += 2
        elif p.get('timeliness') == 'è¿‘æœŸ':
            score += 1
        
        return -score  # é™åº
    
    policies.sort(key=priority)
    
    return policies[:limit]


# æµ‹è¯•
if __name__ == "__main__":
    logger.info("=== æ”¿ç­–å…³é”®è¯æå– V2 ===\n")
    
    policies = get_gov_policy_keywords()
    
    logger.info(f"è·å–åˆ° {len(policies)} æ¡æ”¿ç­–\n")
    
    # æ‰“å°é«˜ä¼˜å…ˆçº§æ”¿ç­–
    logger.info("=== é«˜ä¼˜å…ˆçº§æ”¿ç­–ï¼ˆæ–°æ”¿ç­–+å›½å®¶çº§ï¼‰===\n")
    priority = get_priority_policies(5)
    for i, p in enumerate(priority, 1):
        sectors = p.get('sectors', [])
        s = f" [{', '.join(sectors)}]" if sectors else ""
        logger.info(f"{i}. [{p['level']}][{p['timeliness']}] {p['title'][:40]}{s}")
    
    # æŒ‰çº§åˆ«ç»Ÿè®¡
    logger.info("\n=== æ”¿ç­–çº§åˆ«ç»Ÿè®¡ ===")
    levels = {}
    for p in policies:
        l = p.get('level', 'æœªçŸ¥')
        levels[l] = levels.get(l, 0) + 1
    for l, count in levels.items():
        logger.info(f"  {l}: {count}æ¡")
    
    # æŒ‰æ—¶æ•ˆç»Ÿè®¡
    logger.info("\n=== æ”¿ç­–æ—¶æ•ˆç»Ÿè®¡ ===")
    times = {}
    for p in policies:
        t = p.get('timeliness', 'æœªçŸ¥')
        times[t] = times.get(t, 0) + 1
    for t, count in times.items():
        logger.info(f"  {t}: {count}æ¡")
    
    # æå–é¢†åŸŸ
    logger.info("\n=== æ”¿ç­–å…³æ³¨é¢†åŸŸ ===")
    sectors = get_focus_sectors()
    logger.info(f"  {', '.join(sectors)}")
